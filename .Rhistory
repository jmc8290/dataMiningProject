knitr::opts_chunk$set(echo = TRUE)
full_data <- read.csv('data/data_mining.csv')
head(full_data)
View(full_data)
knitr::opts_chunk$set(echo = TRUE)
library(arules)
data_transactions <- as(as.data.frame(lapply(full_data, function(x) as.logical(x))), "transactions")
itemsets <- apriori(data_transactions, parameter = list(target = 'frequent itemsets', support = 0.6))
rules <- apriori(product_transactions, parameter = list(support = 0.6, confidence = 0.8))
rules <- apriori(data_transactions, parameter = list(support = 0.6, confidence = 0.8))
inspect(itemsets)
library(arules)
tempData <- subset(full_data, select = -X)
data_transactions <- as(as.data.frame(lapply(tempData, function(x) as.logical(x))), "transactions")
itemsets <- apriori(data_transactions, parameter = list(target = 'frequent itemsets', support = 0.6))
rules <- apriori(data_transactions, parameter = list(support = 0.6, confidence = 0.8))
inspect(itemsets)
ruleData <- subset(full_data, select = c(education, marital-status, occupation, race, sex, native-country))
ruleData <- subset(full_data, select = c(education, maritalstatus, occupation, race, sex, native-country))
View(full_data)
ruleData <- subset(full_data, select = c(education, marital.status, occupation, race, sex, native-country))
ruleData <- subset(full_data, select = c(education, marital.status, occupation, race, sex, native.country))
ruleData <- subset(full_data, select = c(education, marital.status, occupation, race, sex, native.country))
ruleData <- as.data.frame(model.matrix(~ . -1, data = ruleData))
head(ruleData)
library(arules)
data_transactions <- as(as.data.frame(lapply(ruleData, function(x) as.logical(x))), "transactions")
itemsets <- apriori(data_transactions, parameter = list(target = 'frequent itemsets', support = 0.6))
rules <- apriori(data_transactions, parameter = list(support = 0.6, confidence = 0.8))
inspect(itemsets)
library(arules)
data_transactions <- as(as.data.frame(lapply(ruleData, function(x) as.logical(x))), "transactions")
itemsets <- apriori(data_transactions, parameter = list(target = 'frequent itemsets', support = 0.01))
rules <- apriori(data_transactions, parameter = list(support = 0.01, confidence = 0.5))
inspect(itemsets)
inspect(rules)
subset(rules, subset = lift > 1.25)
inspect(sort(rules, by = 'lift')[1:10])
rules <- rules[!is.redundant(rules)]
inspect(sort(rules, by = 'lift')[1:10])
nrow(rules)
length(rules)
subset(rules, subset = lift > 1.25)
subset(rules, subset = lift > 1.5)
inspect(sort(rules, by = 'lift')[11:20])
inspect(sort(rules, by = 'lift')[21:30])
inspect(sort(rules, by = 'lift')[31:40])
inspect(sort(rules, by = 'lift')[41:50])
inspect(sort(rules, by = 'lift')[51:])
inspect(sort(rules, by = 'lift')[51:63])
inspect(sort(rules, by = 'lift')[64:75])
subset(rules, items %in% "occupationSales")
inspect(subset(rules, items %in% "occupationSales"))
inspect(sort(subset(rules, items %in% "occupationSales"), by = "lift"))
inspect(sort(subset(rules, items %in% "educationAssoc.voc"), by = "lift"))
knitr::opts_chunk$set(echo = TRUE)
full_data <- read.csv('data/data_mining.csv')
head(full_data)
# 1. Remove unnecessary ID/index column
full_data$X <- NULL
# 2. Replace '?' with NA (for missing values)
full_data[full_data == "?"] <- NA
# 3. Check how many missing values per column
colSums(is.na(full_data))
# 4. Remove rows with missing values
full_data <- na.omit(full_data)
colSums(is.na(full_data))
# 5. Scale numeric columns (regularization)
library(dplyr)
full_data_scaled <- full_data %>%
mutate(across(where(is.numeric), scale))
# 6. Convert character columns to factors
full_data_scaled[sapply(full_data_scaled, is.character)] <-
lapply(full_data_scaled[sapply(full_data_scaled, is.character)], as.factor)
# 7. One-hot encode categorical variables (dummy variables)
library(caret)
dummy <- dummyVars(" ~ .", data = full_data_scaled)
full_data_scaled <- data.frame(predict(dummy, newdata = full_data_scaled))
# 8. Check structure of the processed dataset
str(full_data_scaled)
# 9. Preview cleaned and processed data
head(full_data_scaled)
ruleData <- subset(full_data, select = c(education, marital.status, occupation, race, sex, native.country))
ruleData <- as.data.frame(model.matrix(~ . -1, data = ruleData))
head(ruleData)
library(arules)
data_transactions <- as(as.data.frame(lapply(ruleData, function(x) as.logical(x))), "transactions")
itemsets <- apriori(data_transactions, parameter = list(target = 'frequent itemsets', support = 0.01))
rules <- apriori(data_transactions, parameter = list(support = 0.01, confidence = 0.5))
inspect(itemsets)
inspect(rules)
rules <- rules[!is.redundant(rules)]
inspect(sort(rules, by = 'lift')[1:10])
inspect(sort(rules, by = 'lift')[11:20])
inspect(sort(rules, by = 'lift')[21:30])
inspect(sort(rules, by = 'lift')[31:40])
inspect(sort(rules, by = 'lift')[41:50])
inspect(sort(rules, by = 'lift')[51:63])
inspect(sort(rules, by = 'lift')[64:75])
View(full_data)
knitr::opts_chunk$set(echo = TRUE)
cluster_data <- full_data %>%
cluster_data <- full_data %>%
library(cluster)
library(cluster)
library(dbscan)
library(Rtsne)
library(dplyr)
cluster_data <- full_data %>%
cluster_data <- full_data %>%
select(-c(occupation, relationship, capital.gain, capital.loss, native.country, income))
cluster_data <- full_data %>%
select(-c(occupation, relationship, capital.gain, capital.loss, native.country, income))
gower_dist <- daisy(cluster_data[1:100],
metric = "gower")
gower_dist <- daisy(cluster_data[,1:100],
metric = "gower")
gower_dist <- daisy(cluster_data[1:100,],
metric = "gower")
cluster_data_encoded <- dummy_cols(cluster_data, remove_first_dummy = TRUE)
library(dplyr)
cluster_data_encoded <- dummy_cols(cluster_data, remove_first_dummy = TRUE)
install.packages("fastDummies")
library(fastDummies)
cluster_data_encoded <- dummy_cols(cluster_data, remove_first_dummy = TRUE)
View(cluster_data_encoded)
View(cluster_data)
cluster_data_encoded <- cluster_data_encoded %>%
select(-c(workclass, education, marital.status, race, sex))
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:10){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:10, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:10, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:10){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:10, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:10, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:40){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:40, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:40, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:50){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:50, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:50, sil)
gower_dist <- daisy(cluster_data_encoded[1:1000,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:50){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:50, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:50, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
diss <- numeric(50)
# Loop over number of clusters (from 2 to 50)
for(i in 2:50) {
pam_fit <- pam(gower_mat, diss = TRUE, k = i)  # PAM clustering with k clusters
diss[i] <- sum(pam_fit$clusinfo[, "diss"])  # Sum of dissimilarities within clusters
}
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
diss <- numeric(50)
# Loop over number of clusters (from 2 to 50)
for(i in 2:50) {
pam_fit <- pam(gower_mat, diss = TRUE, k = i)  # PAM clustering with k clusters
diss[i] <- pam_fit$tot.withinss  # Sum of dissimilarities within clusters
}
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
diss <- numeric(50)
# Loop over number of clusters (from 2 to 50)
for(i in 2:50) {
pam_fit <- pam(gower_mat, diss = TRUE, k = i)  # PAM clustering with k clusters
diss[i - 1] <- pam_fit$tot.withinss  # Sum of dissimilarities within clusters
}
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
diss <- numeric(50)
# Loop over number of clusters (from 2 to 50)
for(i in 2:50) {
pam_fit <- pam(gower_mat, diss = TRUE, k = i)  # PAM clustering with k clusters
diss[i - 1] <- pam_fit$tot.diss  # Sum of dissimilarities within clusters
}
pam_fit <- pam(gower_mat, diss = TRUE, k = i)  # PAM clustering with k clusters
View(pam_fit)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:100){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:80){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:80, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:80, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:80){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:80, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:80, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:80){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:80, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:80, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:80){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:80, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:80, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
sil <- c(NA)
for(i in 2:80){
pam_fit <- pam(gower_mat, diss = TRUE, k = i)
sil[i] <- pam_fit$silinfo$avg.width
}
#plot silhouette width
plot(1:80, sil,
xlab = "number of clusters",
ylab = "silhouette width")
lines(1:80, sil)
gower_dist <- daisy(cluster_data_encoded[1:100,],
metric = "gower")
gower_mat <- as.matrix(gower_dist)
pca_result <- prcomp(data, scale. = TRUE)  # Normalize data before PCA
res <- dbscan(cluster_data_encoded, eps = 0.05, minPts = 10)
res
res <- dbscan(cluster_data_encoded, eps = 8, minPts = 10)
res
res <- dbscan(cluster_data_encoded, eps = 8, minPts = 2)
res
res <- dbscan(cluster_data_encoded, eps = 5, minPts = 2)
res
res <- dbscan(cluster_data_encoded, eps = 100, minPts = 2)
res
res <- dbscan(cluster_data_encoded, eps = 100, minPts = 10)
res
res <- dbscan(cluster_data_encoded, eps = 120, minPts = 10)
res
res <- dbscan(cluster_data_encoded, eps = 250, minPts = 10)
res
res <- dbscan(cluster_data_encoded, eps = 250, minPts = 5)
res
